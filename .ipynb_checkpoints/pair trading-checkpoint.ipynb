{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yfinance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-847ae6b7fbb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstattools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregression\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrolling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRollingOLS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0myfinance\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0myf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'yfinance'"
     ]
    }
   ],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from statsmodels.regression.rolling import RollingOLS\n",
    "import yfinance as yf\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_list = ['PEP', 'KO']\n",
    "data = yf.download(\n",
    "    symbol_list, \n",
    "    start='2014-01-01', \n",
    "    end='2015-01-01'\n",
    ")['Adj Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "russell_df = pd.read_csv(\"russell1000pvdata.csv\", error_bad_lines = False)\n",
    "vars = ['open', 'high', 'low', 'close', 'volume']\n",
    "rawdata = {}\n",
    "for tvar in vars:\n",
    "    rawdata[tvar] = russell_df.loc[:, ['tickerid', 'ticker', 'date', tvar]]\n",
    "    rawdata[tvar] = rawdata[tvar].pivot(index = 'date', columns = 'ticker', values = tvar)\n",
    "return_df = (rawdata['close'] / rawdata['close'].shift(1)) - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm;\n",
    "import statsmodels.tsa.stattools as ts\n",
    "(ts.coint(rawdata['close']['PEP'].iloc[200:2200,], rawdata['close']['KO'].iloc[200:2200,]))[1]\n",
    "result = sm.OLS(rawdata['close']['PEP'].iloc[200:2200,],sm.add_constant(rawdata['close']['KO'].iloc[200:2200,])).fit()\n",
    "rawdata['close']['PEPKOspread'] = (rawdata['close']['PEP'] - result.params[1]*rawdata['close']['KO']) -result.params[0]\n",
    "rawdata['close']['PEPKOposition'] = 0\n",
    "rawdata['close'].loc[rawdata['close']['PEPKOspread']>0, 'PEPKOposition'] = -1\n",
    "rawdata['close'].loc[rawdata['close']['PEPKOspread']<0, 'PEPKOposition'] = 1\n",
    "rawdata['close']['PEPKOposition'] = rawdata['close']['PEPKOposition'].shift(1)\n",
    "rawdata['close']['PEPposition'] = rawdata['close']['PEPKOposition']\n",
    "rawdata['close']['KOposition'] = rawdata['close']['PEPKOposition']*result.params[1]*-1\n",
    "rawdata['close']['dailypnl'] = rawdata['close']['KOposition']*return_df['KO'].shift(-1) + rawdata['close']['PEPposition']*return_df['PEP'].shift(-1)\n",
    "rawdata['close']['cumpnl'] = rawdata['close']['dailypnl'].cumsum()\n",
    "plt.plot(rawdata['close']['cumpnl'].values)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####TECHNICAL ANALYSIS STOCHASTIC OSCILLATOR####\n",
    "\n",
    "\n",
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "\n",
    "\n",
    "#Utility method takes in daily % pnl vector and computes portfolio diagnostics\n",
    "#daily % pnl is inputed as a dataframe, with date as index and corresponding pnl for that date as the value\n",
    "def portfolioDiagnostics(signal_df, label):\n",
    "    #NET SECTOR EXPOSURES\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure();\n",
    "    sector_df = pd.read_csv(\"sector.csv\", error_bad_lines = False)\n",
    "    d = sector_df.set_index('ticker').to_dict()\n",
    "    signal_df2 = signal_df.copy(deep=True)\n",
    "    signal_df2.columns = signal_df2.columns.to_series().map(d['sector'])\n",
    "    uniquesector = list(set(signal_df2.columns))\n",
    "    for tsector in uniquesector:\n",
    "        if (str(tsector)=='nan'):\n",
    "            continue;\n",
    "        tmean = signal_df2.loc[:, tsector].sum(axis=1)\n",
    "        tmean[~np.isfinite(tmean)] = 0\n",
    "        plt.plot(tmean.values, label=tsector)\n",
    "        plt.legend();\n",
    "        plt.title(label+\" NET EXPOSURE\")\n",
    "        plt.show(block=False)\n",
    "    return\n",
    "\n",
    "#Utility method takes in daily % pnl vector and computes pnl diagnostics\n",
    "#daily % pnl is inputed as a dataframe, with date as index and corresponding pnl for that date as the value\n",
    "def pnlPerformance(pnl, label):\n",
    "    cumpnl = pnl.cumsum(skipna = True)\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    sharpe = pnl.mean()/np.std(pnl)\n",
    "    sharpe = sharpe*np.sqrt(252)\n",
    "    print(\"\")\n",
    "    print (\"PERFORMANCE STATISTICS FOR \"+label);\n",
    "    print(\"Daily annualized sharpe: \"+str(sharpe))\n",
    "    print (\"Average annual returns: \"+str(pnl.mean()*252*100)+\"%\")\n",
    "    print (\"Total returns: \"+str(pnl.sum()*100)+\"%\");\n",
    "    highwatermark_df = cumpnl.cummax();\n",
    "    drawdown_df = cumpnl - highwatermark_df;\n",
    "    maxdrawdown = drawdown_df.min();\n",
    "    print (\"Max drawdown: \"+str(maxdrawdown*100)+\"%\");\n",
    "    plt.plot(cumpnl.values, label = label);\n",
    "    plt.legend();\n",
    "    plt.show(block=False);\n",
    "    plt.title(\"Cumulative PNL chart\")\n",
    "    #HERE, we compute performance during 'stressed' historical periods\n",
    "    stressedmarkets = dict()\n",
    "    stressedmarkets[\"Covid19\"] = (20200301, 20200317);          #Market crash 1H March 2020\n",
    "    stressedmarkets[\"Dec18\"] = (20181215, 20181231);            #Market crash last 2 weeks\n",
    "    stressedmarkets[\"Fall2015\"] = (20150701, 20150901);         #Taper tantrum / EU debt crisis.  24 Aug 2015 was \"BlackMonday\" for Asian, EU and US markets\n",
    "    stressedmarkets[\"Oct14\"] = (20141001, 20141031);            #Treasury flash crash on 15 Oct 2014\n",
    "    stressedmarkets[\"Aug2013\"] = (20130820, 20130825);          #Flash freeze on 22 Aug 2013\n",
    "\n",
    "    for tkey in stressedmarkets.keys():\n",
    "        mask = pnl.index.to_series().between(stressedmarkets[tkey][0], stressedmarkets[tkey][1])\n",
    "        print(\"Stressed period return during \"+tkey+\":  \"+str(pnl[mask].sum()*100)+\"%\")\n",
    "    print(\"===========================\")\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=======ACTUAL STRATEGY SCRIPT STARTS HERE============================#\n",
    "\n",
    "russell_df = pd.read_csv(\"russell2000pvdata.csv\", error_bad_lines = False)\n",
    "vars = ['open', 'high', 'low', 'close', 'volume']\n",
    "rawdata = {}\n",
    "period = 20           #NUMBER OF TRADING DAYS TO COMPUTE MEAN REVERSION OVER.  THIS IS A PARAMETER FOR FITTING\n",
    "universesize = 2000                 #SIZE OF PORTFOLIO IN NUMBER OF STOCKS.  IF THIS IS MORE THAN 2000, IT WILL GENERALLY JUST BE CAPPED AT 2000 SINCE BASE UNIVERSE IS RUSSELL 2000\n",
    "maxindividualweight = 0.01          #MAXIMUM FRACTION A SINGLE POSITION CAN TAKE UP OF ENTIRE PORTFOLIO.  0.01 MEANS 1%.  i.e. if you have a portfolio of $100 million, max single position size is $1 million\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USING STOCHASTIC OSCILLATOR FOR MR:  MARKET NEUTRAL STRATEGY BASED ON N DAY REVERSION, BASE UNIVERSE IS STOCKS IN RUSSELL 2000\n",
    "for tvar in vars:\n",
    "    rawdata[tvar] = russell_df.loc[:, ['tickerid', 'ticker', 'date', tvar]]\n",
    "    rawdata[tvar] = rawdata[tvar].pivot(index = 'date', columns = 'ticker', values = tvar)\n",
    "    rawdata[tvar] = rawdata[tvar].iloc[:, :universesize]\n",
    "\n",
    "return_df = (rawdata['close'] / rawdata['close'].shift(1)) - 1\n",
    "signal_df = -(return_df - return_df.rolling(period, min_periods = 3).min()) / (return_df.rolling(period, min_periods = 3).max() - return_df.rolling(period, min_periods = 3).min())\n",
    "signal_df = signal_df.subtract(signal_df.mean(axis=1), axis='index')\n",
    "signal_df = signal_df.divide(signal_df.abs().sum(axis=1), axis='index')\n",
    "signal_df = signal_df.shift(1)                                              #TO AVOID FORWARD BIAS.  WE USE YESTERDAY'S INFORMATION TO EXECUTE AT TODAY'S CLOSE PRICES\n",
    "for i in range(3):\n",
    "    signal_df[signal_df > maxindividualweight] = maxindividualweight\n",
    "    signal_df[signal_df < -maxindividualweight] = -maxindividualweight\n",
    "    signal_df = signal_df.subtract(signal_df.mean(axis=1), axis='index')\n",
    "    signal_df = signal_df.divide(signal_df.abs().sum(axis=1), axis='index')\n",
    "pnl_df = signal_df * return_df.shift(-1)                                    #BASED ON YESTERDAY'S INFORMATION, WE EXECUTE AT TODAY'S CLOSE PRICES AND COMPUTE OUR PNL BASED ON TOMORROW'S RETURN\n",
    "pnl = pnl_df.sum(axis=1)\n",
    "pnlPerformance(pnl, \"MARKET NEUTRAL\")\n",
    "marketneutralportfolio = signal_df.copy(deep=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USING MA CROSSOVER:  MOMENTUM SIGNAL\n",
    "signal_df = -(return_df.rolling(3).mean() - return_df.rolling(period, min_periods = 3).mean())\n",
    "signal_df = signal_df.subtract(signal_df.mean(axis=1), axis='index')\n",
    "signal_df = signal_df.divide(signal_df.abs().sum(axis=1), axis='index')\n",
    "signal_df = signal_df.shift(1)                                              #TO AVOID FORWARD BIAS.  WE USE YESTERDAY'S INFORMATION TO EXECUTE AT TODAY'S CLOSE PRICES\n",
    "for i in range(3):\n",
    "    signal_df[signal_df > maxindividualweight] = maxindividualweight\n",
    "    signal_df[signal_df < -maxindividualweight] = -maxindividualweight\n",
    "    signal_df = signal_df.subtract(signal_df.mean(axis=1), axis='index')\n",
    "    signal_df = signal_df.divide(signal_df.abs().sum(axis=1), axis='index')\n",
    "pnl_df = signal_df * return_df.shift(-1)                                    #BASED ON YESTERDAY'S INFORMATION, WE EXECUTE AT TODAY'S CLOSE PRICES AND COMPUTE OUR PNL BASED ON TOMORROW'S RETURN\n",
    "pnl = pnl_df.sum(axis=1)\n",
    "pnlPerformance(pnl, \"MARKET NEUTRAL\")\n",
    "marketneutralportfolio = signal_df.copy(deep=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
